{"componentChunkName":"component---src-templates-page-js","path":"/stringify/api/stream_callback/","result":{"data":{"page":{"html":"<h1 id=\"combining-a-stream-with-a-entire-dataset\" style=\"position:relative;\"><a href=\"#combining-a-stream-with-a-entire-dataset\" aria-label=\"combining a stream with a entire dataset permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Combining a stream with a entire dataset</h1>\n<p>It leverages the stream transform API but input doesn't have to be an readable\nstream and output doesn't have to be a writable stream. Input may be a string\npassed as first argument. Output may be obtained in the callback passed as last\nargument.</p>\n<p>Uses it for convenience in case you are already interacting with a readable\nstream or a writable stream. It is not scalable because it implies that you\neither have all your records in memory and wish to pipe the generated\nCSV into a stream writer or that you have a stream reader generated records and\nwish to obtain a string representing the full CSV text.</p>\n<p>The signature of the <a href=\"https://github.com/adaltas/node-csv/blob/master/packages/csv-stringify/samples/mixed.output_stream.js\">output stream example</a> is <code class=\"language-text\">const stream = stringify(input, [options])</code>. It takes an input string and an options object as arguments and return a readable stream.</p>\n<p><div class=\"gatsby-highlight display-embed-file-highlight\" data-language=\"jsx\"><pre class=\"language-jsx\"><code class=\"language-jsx\"><span class=\"token keyword\">import</span> assert <span class=\"token keyword\">from</span> <span class=\"token string\">'assert'</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token punctuation\">{</span> stringify <span class=\"token punctuation\">}</span> <span class=\"token keyword\">from</span> <span class=\"token string\">'csv-stringify'</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">const</span> data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n<span class=\"token function\">stringify</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n  <span class=\"token punctuation\">[</span> <span class=\"token string\">'1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'2'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'3'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'4'</span> <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">[</span> <span class=\"token string\">'a'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'c'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'d'</span> <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">// Use the readable stream api</span>\n  <span class=\"token punctuation\">.</span><span class=\"token function\">on</span><span class=\"token punctuation\">(</span><span class=\"token string\">'readable'</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">let</span> row<span class=\"token punctuation\">;</span> <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>row <span class=\"token operator\">=</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span><span class=\"token function\">read</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">!==</span> <span class=\"token keyword\">null</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      data<span class=\"token punctuation\">.</span><span class=\"token function\">push</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">// When we are done, test that the parsed records matched what expected</span>\n  <span class=\"token punctuation\">.</span><span class=\"token function\">on</span><span class=\"token punctuation\">(</span><span class=\"token string\">'end'</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    assert<span class=\"token punctuation\">.</span><span class=\"token function\">deepStrictEqual</span><span class=\"token punctuation\">(</span>\n      data<span class=\"token punctuation\">.</span><span class=\"token function\">join</span><span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n      <span class=\"token string\">'1,2,3,4\\na,b,c,d\\n'</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre><div class=\"display-embed-file\"><a href=\"https://github.com/adaltas/node-csv/blob/master/packages/csv-stringify/samples/mixed.output_stream.js\">./packages/csv-stringify/samples/mixed.output_stream.js</a></div></div></p>\n<p>Inversely, the signature of the <a href=\"https://github.com/adaltas/node-csv/blob/master/packages/csv-stringify/samples/mixed.input_stream.js\">input stream example</a> is <code class=\"language-text\">const stream = stringify([options], callback)</code>. It takes an options object and a callback function as arguments and return a writable stream.</p>\n<p><div class=\"gatsby-highlight display-embed-file-highlight\" data-language=\"jsx\"><pre class=\"language-jsx\"><code class=\"language-jsx\"><span class=\"token keyword\">import</span> assert <span class=\"token keyword\">from</span> <span class=\"token string\">'assert'</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token punctuation\">{</span> stringify <span class=\"token punctuation\">}</span> <span class=\"token keyword\">from</span> <span class=\"token string\">'csv-stringify'</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Create the parser</span>\n<span class=\"token keyword\">const</span> stringifier <span class=\"token operator\">=</span> <span class=\"token function\">stringify</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n  <span class=\"token literal-property property\">delimiter</span><span class=\"token operator\">:</span> <span class=\"token string\">':'</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">err<span class=\"token punctuation\">,</span> data</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n  assert<span class=\"token punctuation\">.</span><span class=\"token function\">deepStrictEqual</span><span class=\"token punctuation\">(</span>\n    data<span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'root:x:0:0:root:/root:/bin/bash\\n'</span> <span class=\"token operator\">+</span>\n    <span class=\"token string\">'someone:x:1022:1022::/home/someone:/bin/bash\\n'</span>\n  <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">// Write records to the stream</span>\nstringifier<span class=\"token punctuation\">.</span><span class=\"token function\">write</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span> <span class=\"token string\">'root'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'x'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'0'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'0'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'root'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'/root'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'/bin/bash'</span> <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nstringifier<span class=\"token punctuation\">.</span><span class=\"token function\">write</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span> <span class=\"token string\">'someone'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'x'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'1022'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'1022'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">,</span><span class=\"token string\">'/home/someone'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'/bin/bash'</span> <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">// Close the writable stream</span>\nstringifier<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre><div class=\"display-embed-file\"><a href=\"https://github.com/adaltas/node-csv/blob/master/packages/csv-stringify/samples/mixed.output_stream.js\">./packages/csv-stringify/samples/mixed.output_stream.js</a></div></div></p>","frontmatter":{"title":"Combining the stream API with a entire dataset","description":"Replace the writable stream with a string or buffer and the readable stream with a callback function.","keywords":["csv","stringify","api","stream","callback","function","mixin"]},"headings":[],"fields":{"edit_url":"https://github.com/adaltas/node-csv-docs/edit/master/src/md/stringify/api/stream_callback.md","slug":"/stringify/api/stream_callback/"}}},"pageContext":{}},"staticQueryHashes":["421902736"],"slicesMap":{}}